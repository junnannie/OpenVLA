## 多模态具身智能大模型（OpenVLA）复现与微调改进



Transformer 后涌现出一系列大模型，其中以GPT 为代表的 Decoder-Only 架构大模型在泛化性、zero-shoe 能力上取得巨大进展，随后的CLIP、LLAVA 等多模态工作更是让大模型有了世界理解能力，使得大模型控制机器人成为可能。我聚焦于前沿VLA 模型，复现并微调改进了开源SOTA 模型 OpenVLA：

1. **OpenVLA复现与仿真验证**﻿﻿﻿：﻿﻿复现 OpenVLA 模型，并利用仿真环境构建多模态输入与动作输出的端到端训练流程，验证模型在物体操控任务中的泛化性。

2. **LIBERO数据集的LoRA微调**：针对仿真环境与预训练数据的偏移，基于HuggingFace工具链设计LORA微调方案，冻结主干网络参数，仅训练低秩适配层，实现模型在有限数据下的快速适配，微调后任务成功率提升23%。

3. **轻量化部署方案设计**：基于阿里云搭建 A10 GPU 推理服务，采用8bit量化技术将模型体积缩减至原始尺寸的28%，在保持了92% 的原始模型性能的基础上大幅提升了推理速度。



### 实际效果演示

